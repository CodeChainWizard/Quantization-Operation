{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2369,  0.2868, -0.1640, -0.3524],\n",
      "        [ 0.9579, -0.0910, -0.0846,  1.2647],\n",
      "        [ 0.4284,  0.0883,  1.3122, -0.8039],\n",
      "        [ 1.3006, -1.2052,  0.2557, -0.8690]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "original_weight = torch.randn((4,4))\n",
    "print(original_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantized weight: tensor([[  18.,   23.,  -23.,  -42.],\n",
      "        [  91.,  -15.,  -15.,  122.],\n",
      "        [  37.,    3.,  127.,  -87.],\n",
      "        [ 126., -128.,   20.,  -94.]])\n",
      "\n",
      "\n",
      "scale: 0.009872203247219909\n",
      "\n",
      "\n",
      "zero point: -6\n",
      "tensor([[ 0.2369,  0.2863, -0.1678, -0.3554],\n",
      "        [ 0.9576, -0.0888, -0.0888,  1.2636],\n",
      "        [ 0.4245,  0.0888,  1.3130, -0.7996],\n",
      "        [ 1.3031, -1.2044,  0.2567, -0.8688]])\n",
      "tensor(5.6245e-06)\n"
     ]
    }
   ],
   "source": [
    "# Now, we define two functions first for quantization and second for de-quantization.\n",
    "\n",
    "def asymmetric_quantization(original_weight):\n",
    "    # define the data type that you want to quantize. In our example, it's INT8.\n",
    "    quantized_data_type = torch.int8\n",
    "\n",
    "    # Get Wmax and Wmin value.\n",
    "    Wmax = original_weight.max().item()\n",
    "    Wmin = original_weight.min().item()\n",
    "\n",
    "    # Get Qmax and Qmin value.\n",
    "    Qmax = torch.iinfo(quantized_data_type).max\n",
    "    Qmin = torch.iinfo(quantized_data_type).min\n",
    "\n",
    "    # Calculate the Scale value using the scale formual.\n",
    "    S = (Wmax - Wmin) / (Qmax - Qmin)\n",
    "\n",
    "    # Calculate the zero point value using zero point formula.\n",
    "    Z = Qmin - (Wmin/S)\n",
    "\n",
    "    # Check if the Z value is out of the range.\n",
    "    if Z < Qmin:\n",
    "        Z = Qmin\n",
    "    elif Z > Qmax:\n",
    "        Z = Qmax\n",
    "    else:\n",
    "        # Zero point datatypes should be INT8 same as the Quantized value.\n",
    "        Z = int(round(Z))\n",
    "\n",
    "    # We have original_weight, scale and zero_point, now we can calculate the Quantized weight\n",
    "    quantized_weight = (original_weight/S) + Z\n",
    "\n",
    "    # We'll also round it and also use the torch clamp function to ensure the quantized weight doesn't goes out of range and should remain within Qmin and Qmax.\n",
    "    quantized_weight = torch.clamp(torch.round(quantized_weight), Qmin, Qmax)\n",
    "\n",
    "    # Finally cast the datatype to INT8\n",
    "    quantized_data_type = quantized_weight.to(quantized_data_type)\n",
    "\n",
    "    # return the final quantized weight.\n",
    "    return quantized_weight, S, Z\n",
    "\n",
    "def asasymmetric_dequantization(quantized_weight, scale, zero_point):\n",
    "    # Also make sure to convert quantized_weight to float as substraction between two INT8 values (quantized_weight and zero_point) will give unwanted result. \n",
    "\n",
    "    dequantized_weight = scale * (quantized_weight.to(torch.float32) - zero_point)\n",
    "\n",
    "    return dequantized_weight\n",
    "\n",
    "quantized_weight, scale, zero_point = asymmetric_quantization(original_weight)\n",
    "print(f\"quantized weight: {quantized_weight}\")\n",
    "print(\"\\n\")\n",
    "print(f\"scale: {scale}\")\n",
    "print(\"\\n\")\n",
    "print(f\"zero point: {zero_point}\")\n",
    "\n",
    "\n",
    "dequantized_weight = asasymmetric_dequantization(quantized_weight, scale, zero_point)\n",
    "print(dequantized_weight)\n",
    "\n",
    "quantized_error = (dequantized_weight - original_weight).square().mean();\n",
    "print(quantized_error);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
